Dataset:
  train_data_path: "C://Machine Learning//Datasets//flowers//train_data.json"  # Path to json file with train data
  val_data_path: "C://Machine Learning//Datasets//flowers//val_data.json"  # Path to json file with val data
  classes_path: "C://Machine Learning//Datasets//flowers//classes.txt"  # Path to .txt file with list of classes
  num_classes: 5  # Number of classes
Train:
  lr_scheduler:
    lr_init: 0.001  # Initial learning rate
    lr_end: 0.0001  # Final learning rate
    StepDecay:
      use: True  # Use StepDecay as learning rate scheduler
      epoch_steps: [2, 4, 6]  # Epoch number for decreasing leraning rate
  batch_size: 4  # Batch size
  epochs: 10  # Number of epochs
  eval_per_epoch: 5  # Number of evals on the validation data during an epoch
  image_size: [224, 224]  # Input image size. Divisible by 32. Minimum image size is [128,128]
  channels: 3  # Number of channels of the input image
  optimizer: "adam"  # Optimization algorithm. Supported: sgd | adam
  arch: "resnet50"  # Neural net architecture. Supporeted: resnet18 | resnet34 | resnet50 | resnet101 | resnet152 | mobilenet_v1 | mobilenet_v2
  pretrained: ""  # Path to pretrained weights
  device: 0  # GPU id
Augmentation:  # Augmentation methods. In each method value p is probability of using that method
  RandomCrop:
    p: 0.0
  RandomHorizontalFlip:
    p: 0.0
  RandomRotate:
    p: 0.0
    angle: 30
  RandomBrightness:
    p: 0.0
    low_value: 0.5
    high_value: 4.0

Logging:
  tb_logdir: "C://Machine Learning//train_logs//Classification Networks PyTorch//flowers//run3//tb_logs"  # tensorboard log directory
  ckpt_dir: "C://Machine Learning//train_logs//Classification Networks PyTorch//flowers//run3//checkpoints"  # directory for storing checkpoints
